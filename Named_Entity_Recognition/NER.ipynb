{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Idea: Named Entity Recognition (NER) with BiLSTM + CRF\n",
    "\n",
    "### Overview\n",
    "\n",
    "This time, instead of classifying the sentiment of text, we’ll work on Named Entity Recognition (NER). The goal is to extract entities like names, locations, organizations, or dates from text.\n",
    "\n",
    "For this project, we’ll use a BiLSTM + CRF model (Bidirectional LSTM with Conditional Random Fields). This is a classic NLP architecture, different from Transformers but still widely used in many practical NLP tasks.\n",
    "\n",
    "### Keypoints:\n",
    "\n",
    "- Task: Named Entity Recognition (NER) – Identify entities in a sentence (like “Barack Obama” -> PERSON).\n",
    "- Architecture: BiLSTM + CRF – A different model from Transformers.\n",
    "- Dataset: CoNLL-2003, a common dataset for NER.\n",
    "- Libraries: We’ll use PyTorch for building the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 983k/983k [00:00<00:00, 5.48MB/s]\n",
      "Generating train split: 100%|██████████| 14041/14041 [00:01<00:00, 13912.71 examples/s]\n",
      "Generating validation split: 100%|██████████| 3250/3250 [00:00<00:00, 13017.39 examples/s]\n",
      "Generating test split: 100%|██████████| 3453/3453 [00:00<00:00, 12440.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the CoNLL-2003 dataset\n",
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "# Explore the dataset\n",
    "print(dataset[\"train\"][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
